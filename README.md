# Fairness-In-ML

In this notebook, I will try to 
==> Increase awareness of different types of biases that can manifest in model data.
==> Explore feature data to proactively identify potential sources of bias before training a model.
==> Evaluate model performace by subgroup rather than in aggregate.
